
â–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ•—â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘
â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–‘â–‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–‘â–‘â•šâ•â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•‘â–‘â•šâ•â•â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–‘â–‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–‘â–‘â•šâ–ˆâ–ˆâ•”â•â–‘â•šâ–ˆâ–ˆâ•”â•â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â•šâ•â•â–‘â–‘â–‘â–‘â–‘â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•â–‘â–‘â•šâ•â•â•šâ•â•â•â•â•â•â–‘â–‘â•šâ•â•â•â•â•â–‘â–‘â–‘â–‘â•šâ•â•â–‘â–‘â–‘â•šâ•â•â–‘â–‘â•šâ•â•â•â•â•â•â–‘
#                Â© Copyright 2025
#            âœˆ https://t.me/mead0ws_modules

# scope: hikka_only
# scope: hikka_min 1.3.3
# meta developer: @mead0ws_modules
# meta banner: https://x0.at/eoIh.jpg


import requests
from telethon import events
from .. import loader, utils

@loader.tds
class GPTMod(loader.Module):
    """ĞœĞ¾Ğ´ÑƒĞ»ÑŒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ GPT"""
    strings = {"name": "CablyAI"}

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "model",
                "",
                lambda: "ĞœĞ¾Ğ´ĞµĞ»ÑŒ GPT Ğ´Ğ»Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ",
                validator=loader.validators.String()
            ),
        )

    async def gptcmd(self, event):
        """ĞœĞ¾Ğ´ÑƒĞ»ÑŒ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ ChatGPT Ğ¿Ñ€ÑĞ¼Ğ¾ Ğ² Telegram. \nĞĞ²Ñ‚Ğ¾Ñ€: @maximtrous"""
        args = utils.get_args_raw(event)
        if not args:
            await event.reply("ĞĞµÑ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°")
            return

        model = self.config.get("model")

        if not model:
            await event.reply("ĞœĞ¾Ğ´ĞµĞ»ÑŒ GPT Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ° Ğ² ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğµ")
            return

        data = {
            "model": model,
            "messages": [
                {"role": "user", "content": args}
            ]
        }

        response = requests.post("https://cablyai.com/v1/chat/completions", headers={
            'Authorization': 'Bearer sk-csPV6DEqRj07V4jGxPvq0NomUcfo6LIxO_rlxBMuenGaebco',
            'Content-Type': 'application/json',
        }, json=data)

        if response.status_code == 200:
            answer = response.json()["choices"][0]["message"]["content"]
            await event.edit(f"<b><emoji document_id=5974038293120027938>ğŸ‘¤</emoji> Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: <code>{args}</code></b>\n\n<b><emoji document_id=5199682846729449178>ğŸ¤–</emoji> ĞÑ‚Ğ²ĞµÑ‚: {answer}</b>", parse_mode="HTML")
        else:
            await event.reply("ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ Ğº GPT")
